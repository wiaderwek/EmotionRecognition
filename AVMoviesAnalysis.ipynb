{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Input, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "class AVAnalysisModel():   \n",
    "    def __init__(self, seq_length, load_model=False):\n",
    "        self.seq_length = seq_length\n",
    "        self.input_shape = (seq_length, 80, 80, 3)\n",
    "        \n",
    "        self.model = self.lrcn()\n",
    "        \n",
    "        if load_model:\n",
    "            self.load_model()\n",
    "        else:\n",
    "            #compile ony if don't load model to prevent losing optimizer states\n",
    "            optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "            self.model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def lrcn(self):\n",
    "        \"\"\"Build a CNN into RNN.\n",
    "        Starting version from:\n",
    "            https://github.com/udacity/self-driving-car/blob/master/\n",
    "                steering-models/community-models/chauffeur/models.py\n",
    "        Heavily influenced by VGG-16:\n",
    "            https://arxiv.org/abs/1409.1556\n",
    "        Also known as an LRCN:\n",
    "            https://arxiv.org/pdf/1411.4389.pdf\n",
    "        \"\"\"\n",
    "        def add_default_block(model, kernel_filters, init, reg_lambda):\n",
    "\n",
    "            # conv\n",
    "            model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same',\n",
    "                                             kernel_initializer=init, kernel_regularizer=l2(l=reg_lambda))))\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "            model.add(TimeDistributed(Activation('relu')))\n",
    "            # conv\n",
    "            model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same',\n",
    "                                             kernel_initializer=init, kernel_regularizer=l2(l=reg_lambda))))\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "            model.add(TimeDistributed(Activation('relu')))\n",
    "            # max pool\n",
    "            model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "            return model\n",
    "\n",
    "        initialiser = 'glorot_uniform'\n",
    "        reg_lambda  = 0.001\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # first (non-default) block\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same',\n",
    "                                         kernel_initializer=initialiser, kernel_regularizer=l2(l=reg_lambda)),\n",
    "                                  input_shape=self.input_shape))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=initialiser, kernel_regularizer=l2(l=reg_lambda))))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        # 2nd-5th (default) blocks\n",
    "        #model = add_default_block(model, 64,  init=initialiser, reg_lambda=reg_lambda)\n",
    "        #model = add_default_block(model, 128, init=initialiser, reg_lambda=reg_lambda)\n",
    "        #model = add_default_block(model, 256, init=initialiser, reg_lambda=reg_lambda)\n",
    "        #model = add_default_block(model, 512, init=initialiser, reg_lambda=reg_lambda)\n",
    "        model = add_default_block(model, 92, init=initialiser, reg_lambda=reg_lambda)\n",
    "        model = add_default_block(model, 196, init=initialiser, reg_lambda=reg_lambda)\n",
    "        \n",
    "        # LSTM output head\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(len(VideoClass), activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.model.load_weights(MODEL_FILE)\n",
    "        try:\n",
    "            self.model.load_weights(MODEL_FILE)\n",
    "            print('Loaded model from file.')\n",
    "        except:\n",
    "            print('Unable to load model from file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from video_analysis_constants import *\n",
    "from video_dataset import *\n",
    "\n",
    "\n",
    "def train(seq_length, load_model=False, image_shape=None,\n",
    "          load_to_memory=False, batch_size=32, nb_epoch=100):\n",
    "    \n",
    "    # Helper: TensorBoard\n",
    "    tb = TensorBoard(log_dir=os.path.join(OUT_FOLDER, 'logs'))\n",
    "\n",
    "    # Helper: Stop when we stop learning.\n",
    "    early_stopper = EarlyStopping(patience=5)\n",
    "    \n",
    "    #Helper: Save the model during training\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=MODEL_FILE,\n",
    "        monitor='val_acc',\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    if image_shape is None:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length\n",
    "        )\n",
    "    else:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            image_shape=image_shape\n",
    "        )\n",
    "\n",
    "    # Get samples per epoch.\n",
    "    # Multiply by PERCENT_OF_TRAIN to attempt to guess how much of data.data is the train set.\n",
    "    steps_per_epoch = (len(data.data) * PERCENT_OF_TRAIN) // batch_size\n",
    "\n",
    "    if load_to_memory:\n",
    "        # Get data.\n",
    "        X, y, X_test, y_test = data.get_all_sequences_in_memory(PERCENT_OF_TRAIN)\n",
    "    else:\n",
    "        # Get generators.\n",
    "        generator, val_generator = data.get_generators(batch_size, PERCENT_OF_TRAIN)\n",
    "\n",
    "    # Get the model.\n",
    "    rm = AVAnalysisModel(seq_length, load_model)\n",
    "    \n",
    "\n",
    "    # Fit!\n",
    "    if load_to_memory:\n",
    "        # Use standard fit.\n",
    "        rm.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, checkpointer],\n",
    "            epochs=nb_epoch)\n",
    "    else:\n",
    "        # Use fit generator.\n",
    "        rm.model.fit_generator(\n",
    "            generator=generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            callbacks=[tb, checkpointer],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=40,\n",
    "            workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "seq_length = 40\n",
    "batch_size = 32\n",
    "nb_epoch = 1000\n",
    "image_shape = (80, 80, 3)\n",
    "load_to_memory=False\n",
    "#train(seq_length, load_model=load_model, image_shape=image_shape, load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionAnalyser():\n",
    "    def __init__(self, load_model=True):\n",
    "        seq_length = 40\n",
    "        \n",
    "        self.model = AVAnalysisModel(seq_length, load_model)\n",
    "        \n",
    "    def predict(self, seq_length, image_shape, video_dir, video_name):\n",
    "        # Get the data and process it.\n",
    "        if image_shape is None:\n",
    "            data = DataSet(seq_length=seq_length)\n",
    "        else:\n",
    "            data = DataSet(seq_length=seq_length, image_shape=image_shape)\n",
    "        \n",
    "        # Extract the sample from the data.\n",
    "        sample = data.get_frames_to_predict(video_dir, video_name)\n",
    "        \n",
    "        # Predict!\n",
    "        prediction = self.model.model.predict(np.expand_dims(sample, axis=0))\n",
    "        print(prediction)\n",
    "        print(np.argmax(prediction[0]))\n",
    "        return np.argmax(prediction[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from file.\n",
      "[[0.01119245 0.0014576  0.01864872 0.76337546 0.2053257 ]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "ea = EmotionAnalyser()\n",
    "seq_length = 40\n",
    "image_shape = (80, 80, 3)\n",
    "video_dir = \"/home/tomasz/Dokumenty/shared/predict\"\n",
    "video_name = \"ACCEDE00018\"\n",
    "pre = ea.predict(40, (80, 80, 3), video_dir, video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
