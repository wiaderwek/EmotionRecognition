{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from subprocess import call\n",
    "from copy import copy\n",
    "import threading\n",
    "\n",
    "\n",
    "PATH_TO_PROJECT = os.getcwd()\n",
    "PATH_TO_DATA = \"/home/tomasz/Dokumenty/shared/\"\n",
    "DATASET_FOLDER = \"data\"\n",
    "EXTRACTED_DATA_FOLDER = \"extracted_data\"\n",
    "DATASET_RESULT_FILE = \"ACCEDEranking.txt\"\n",
    "VIDO_EXTENSION = \".mp4\"\n",
    "PATH_TO_DATASET = os.path.join(PATH_TO_DATA, DATASET_FOLDER)\n",
    "VIDEO_CLASSES = [\"Neutral\", \"LALV\", \"LAHV\", \"HALV\", \"HAHV\"]\n",
    "MIN_NEUTRAL_LEVEL_VALUE = 3600\n",
    "MAX_NEUTRAL_LEVEL_VALUE = 6300\n",
    "SPLIT_LEVEL = 5000\n",
    "\n",
    "FRAME_SIZE = 100\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "class ValueLevel(Enum):\n",
    "    Low = 1\n",
    "    LowN = 2\n",
    "    HighN = 3\n",
    "    High = 4\n",
    "    \n",
    "class VideoClass(Enum):\n",
    "    Neutral = 1\n",
    "    LALV = 2\n",
    "    LAHV = 3\n",
    "    HALV = 4\n",
    "    HAHV = 5\n",
    "    \n",
    "class threadsafe_iterator:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.iterator)\n",
    "\n",
    "def threadsafe_generator(func):\n",
    "    \"\"\"Decorator\"\"\"\n",
    "    def gen(*a, **kw):\n",
    "        return threadsafe_iterator(func(*a, **kw))\n",
    "    return gen\n",
    "    \n",
    "\n",
    "class DataSet():\n",
    "    def __init__(self, seq_length=40, image_shape=(224, 224, 3)):\n",
    "        \n",
    "        \"\"\"Constructor.\n",
    "        seq_length = (int) the number of frames to consider\n",
    "        \"\"\"\n",
    "        self.path_to_dataset = os.path.join(PATH_TO_DATA, DATASET_FOLDER)\n",
    "        self.path_to_extracted_data = os.path.join(PATH_TO_DATA, EXTRACTED_DATA_FOLDER)\n",
    "        self.seq_length = seq_length\n",
    "        self.max_frames = MAX_FRAMES  # max number of frames a video can have for us to use it\n",
    "        # Get the data.\n",
    "        self.data = self.get_data()\n",
    "\n",
    "        # Now do some minor data cleaning.\n",
    "        self.data = self.clean_data()\n",
    "\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "    def get_data(self):\n",
    "        data = []\n",
    "        path_to_result = os.path.join(PATH_TO_DATA, DATASET_RESULT_FILE)\n",
    "        list_of_results = open(path_to_result).readlines()\n",
    "        list_of_results.pop(0)\n",
    "        for res in list_of_results:\n",
    "            splitted_res = res.split(\"\\t\")\n",
    "            video_name = splitted_res[1]\n",
    "            video_name = video_name[:-4]\n",
    "            valency = splitted_res[2]\n",
    "            arousal = splitted_res[3]\n",
    "            emotion_class = DataSet.get_class_for_arousal_and_valency(int(arousal), int(valency))\n",
    "            number_of_frames = self.extract_data_for_video(video_name)\n",
    "            #print(video_name + \": \" + arousal + \", \" + valency + \", \" + emotion_class.name + \", \" + str(number_of_frames))\n",
    "            data.append([video_name, int(valency), int(arousal), emotion_class, number_of_frames])\n",
    "\n",
    "        return data\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_class_for_arousal_and_valency(arousal, valency):\n",
    "        if arousal < MIN_NEUTRAL_LEVEL_VALUE:\n",
    "            if valency < SPLIT_LEVEL:\n",
    "                return VideoClass.LALV\n",
    "            else:\n",
    "                return VideoClass.LAHV\n",
    "        elif arousal < SPLIT_LEVEL:\n",
    "            if valency < MIN_NEUTRAL_LEVEL_VALUE:\n",
    "                return VideoClass.LALV\n",
    "            elif valency < MAX_NEUTRAL_LEVEL_VALUE:\n",
    "                return VideoClass.Neutral\n",
    "            else:\n",
    "                return VideoClass.LAHV\n",
    "        elif arousal < MAX_NEUTRAL_LEVEL_VALUE:\n",
    "            if valency < MIN_NEUTRAL_LEVEL_VALUE:\n",
    "                return VideoClass.HALV\n",
    "            elif valency < MAX_NEUTRAL_LEVEL_VALUE:\n",
    "                return VideoClass.Neutral\n",
    "            else:\n",
    "                return VideoClass.HAHV\n",
    "        else:\n",
    "            if valency < SPLIT_LEVEL:\n",
    "                return VideoClass.HALV\n",
    "            else:\n",
    "                return VideoClass.HAHV\n",
    "            \n",
    "    def extract_data_for_video(self, video_name):\n",
    "        if not os.path.isdir(self.path_to_extracted_data):\n",
    "            os.mkdir(self.path_to_extracted_data)\n",
    "        if not os.path.isdir(os.path.join(self.path_to_extracted_data, video_name)):\n",
    "            os.mkdir(os.path.join(self.path_to_extracted_data, video_name))\n",
    "            \n",
    "        if not self.check_if_video_is_extracted(video_name):\n",
    "            src = os.path.join(self.path_to_dataset, video_name + VIDO_EXTENSION)\n",
    "            dest = os.path.join(self.path_to_extracted_data, video_name,\n",
    "                        '%04d.jpg')\n",
    "            call([\"ffmpeg\", \"-i\", src, dest])\n",
    "        return len(self.get_frames_for_video(video_name))\n",
    "            \n",
    "    def get_frames_for_video(self, video_name):\n",
    "        images = sorted(glob.glob(os.path.join(self.path_to_extracted_data, video_name, '*jpg')))\n",
    "        return images\n",
    "        \n",
    "    def check_if_video_is_extracted(self, video_name):\n",
    "        return bool(os.path.exists(os.path.join(self.path_to_extracted_data, video_name,\n",
    "                               '0001.jpg')))\n",
    "        \n",
    "    def clean_data(self):\n",
    "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
    "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
    "        data_clean = []\n",
    "        for item in self.data:\n",
    "            if int(item[4]) >= self.seq_length and int(item[4]) <= self.max_frames:\n",
    "                data_clean.append(item)\n",
    "\n",
    "        return data_clean\n",
    "    \n",
    "    def split_train_test(self, percent_of_train):\n",
    "        number_of_train = int(len(self.data) * percent_of_train)\n",
    "        y = copy(self.data)\n",
    "        random.shuffle(y)\n",
    "        train = y[:number_of_train]\n",
    "        test = y[number_of_train:]\n",
    "        \n",
    "        return train, test\n",
    "    \n",
    "    def build_image_sequence(self, frames):\n",
    "        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n",
    "        return [process_image(x, self.image_shape) for x in frames]\n",
    "    \n",
    "    def get_all_sequences_in_memory(self, train_or_test, precent_of_train):\n",
    "        train, test = self.split_train_test(precent_of_train)\n",
    "        data = train if train_or_test == \"train\" else test\n",
    "        \n",
    "        X, y = [], []\n",
    "        \n",
    "        for row in data:\n",
    "            frames = self.get_frames_for_video(row[0])\n",
    "            frames = self.rescale_list(frames, self.seq_length)\n",
    "            sequence = self.build_image_sequence(frames)\n",
    "            X.append(sequence)\n",
    "            y.append(row[3])\n",
    "            \n",
    "        np.array(X), np.array(y)\n",
    "        \n",
    "    @threadsafe_generator\n",
    "    def frame_generator(self, batch_size, train_test, precent_of_train):\n",
    "        train, test = self.split_train_test(precent_of_train)\n",
    "        data = train if train_or_test == \"train\" else test\n",
    "        \n",
    "        while 1:\n",
    "            X, y = [], []\n",
    "            \n",
    "            for _ in range(batch_size):\n",
    "                sample = random.choice(data)\n",
    "                frames = self.get_frames_for_video(row[0])\n",
    "                frames = self.rescale_list(frames, self.seq_length)\n",
    "                sequence = self.build_image_sequence(frames)\n",
    "                X.append(sequence)\n",
    "                y.append(row[3])\n",
    "            \n",
    "            \n",
    "            yield np.array(X), np.array(y)\n",
    "            \n",
    "            \n",
    "    def rescale_list(input_list, size):\n",
    "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
    "        if we want a list of size 5 and we have a list of size 25, return a new\n",
    "        list of size five which is every 5th element of the origina list.\"\"\"\n",
    "        assert len(input_list) >= size\n",
    "\n",
    "        # Get the number to skip between iterations.\n",
    "        skip = len(input_list) // size\n",
    "\n",
    "        # Build our new output.\n",
    "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
    "\n",
    "        # Cut off the last one if needed.\n",
    "        return output[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "class AVAnalysisModel():   \n",
    "    def __init__(self, seq_length, saved_model=None):\n",
    "        self.seq_length = seq_length\n",
    "        self.input_shape = (seq_length, 80, 80, 3)\n",
    "        \n",
    "        if saved_model is not None:\n",
    "            self.model = load_model(self.saved_model)\n",
    "        else:\n",
    "            self.model = self.lrcn()\n",
    "    \n",
    "    def lrcn(self):\n",
    "        \"\"\"Build a CNN into RNN.\n",
    "        Starting version from:\n",
    "            https://github.com/udacity/self-driving-car/blob/master/\n",
    "                steering-models/community-models/chauffeur/models.py\n",
    "        Heavily influenced by VGG-16:\n",
    "            https://arxiv.org/abs/1409.1556\n",
    "        Also known as an LRCN:\n",
    "            https://arxiv.org/pdf/1411.4389.pdf\n",
    "        \"\"\"\n",
    "        def add_default_block(model, kernel_filters, init, reg_lambda):\n",
    "\n",
    "            # conv\n",
    "            model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same',\n",
    "                                             kernel_initializer=init, kernel_regularizer=l2(l=reg_lambda))))\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "            model.add(TimeDistributed(Activation('relu')))\n",
    "            # conv\n",
    "            model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same',\n",
    "                                             kernel_initializer=init, kernel_regularizer=l2(l=reg_lambda))))\n",
    "            model.add(TimeDistributed(tf.nn.batch_normalization()))\n",
    "            model.add(TimeDistributed(Activation('relu')))\n",
    "            # max pool\n",
    "            model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "            return model\n",
    "\n",
    "        initialiser = 'glorot_uniform'\n",
    "        reg_lambda  = 0.001\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # first (non-default) block\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same',\n",
    "                                         kernel_initializer=initialiser, kernel_regularizer=l2(l=reg_lambda)),\n",
    "                                  input_shape=self.input_shape))\n",
    "        model.add(TimeDistributed(tf.nn.batch_normalization()))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=initialiser, kernel_regularizer=l2(l=reg_lambda))))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        # 2nd-5th (default) blocks\n",
    "        model = add_default_block(model, 64,  init=initialiser, reg_lambda=reg_lambda)\n",
    "        model = add_default_block(model, 128, init=initialiser, reg_lambda=reg_lambda)\n",
    "        model = add_default_block(model, 256, init=initialiser, reg_lambda=reg_lambda)\n",
    "        model = add_default_block(model, 512, init=initialiser, reg_lambda=reg_lambda)\n",
    "\n",
    "        # LSTM output head\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(self.nb_classes, activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "PERCENT_OF_TRAIN = 0.7\n",
    "\n",
    "def train(seq_length, saved_model=None, image_shape=None,\n",
    "          load_to_memory=False, batch_size=32, nb_epoch=100, loaded_data=None):\n",
    "    \n",
    "    # Helper: TensorBoard\n",
    "    tb = TensorBoard(log_dir=os.path.join('data', 'logs'))\n",
    "\n",
    "    # Helper: Stop when we stop learning.\n",
    "    early_stopper = EarlyStopping(patience=5)\n",
    "\n",
    "    # Get the data and process it.\n",
    "    if loaded_data is not None:\n",
    "        data = loaded_data\n",
    "    elif image_shape is None:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length\n",
    "        )\n",
    "    else:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            image_shape=image_shape\n",
    "        )\n",
    "\n",
    "    # Get samples per epoch.\n",
    "    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
    "    steps_per_epoch = (len(data.data) * 0.7) // batch_size\n",
    "\n",
    "    if load_to_memory:\n",
    "        # Get data.\n",
    "        X, y = data.get_all_sequences_in_memory('train', PERCENT_OF_TRAIN)\n",
    "        X_test, y_test = data.get_all_sequences_in_memory('test', PERCENT_OF_TRAIN)\n",
    "    else:\n",
    "        # Get generators.\n",
    "        generator = data.frame_generator(batch_size, 'train', PERCENT_OF_TRAIN)\n",
    "        val_generator = data.frame_generator(batch_size, 'test', PERCENT_OF_TRAIN)\n",
    "\n",
    "    # Get the model.\n",
    "    rm = AVAnalysisModel(seq_length, saved_model)\n",
    "\n",
    "    # Fit!\n",
    "    if load_to_memory:\n",
    "        # Use standard fit.\n",
    "        rm.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger],\n",
    "            epochs=nb_epoch)\n",
    "    else:\n",
    "        # Use fit generator.\n",
    "        rm.model.fit_generator(\n",
    "            generator=generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger, checkpointer],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=40,\n",
    "            workers=4)\n",
    " \n",
    "    now = time.strftime(\"%c\")\n",
    "    rm.save(str(now) + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = None  # None or weights file\n",
    "seq_length = 40\n",
    "load_to_memory = False  # pre-load the sequences into memory\n",
    "batch_size = 32\n",
    "nb_epoch = 1000\n",
    "image_shape = (80, 80, 3)\n",
    "data = DataSet= DataSet(\n",
    "            seq_length=seq_length,\n",
    "            image_shape=image_shape\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "batch_normalization() missing 6 required positional arguments: 'x', 'mean', 'variance', 'offset', 'scale', and 'variance_epsilon'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-da9579c09568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train(seq_length, saved_model=saved_model, image_shape=image_shape,\n\u001b[0;32m----> 2\u001b[0;31m           load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch, loaded_data=data)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-bd6e4694108d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(seq_length, saved_model, image_shape, load_to_memory, batch_size, nb_epoch, loaded_data)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Get the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mrm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAVAnalysisModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Fit!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-9a4a2d0362fc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, seq_length, saved_model)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlrcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-9a4a2d0362fc>\u001b[0m in \u001b[0;36mlrcn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m                                          kernel_initializer=initialiser, kernel_regularizer=l2(l=reg_lambda)),\n\u001b[1;32m     57\u001b[0m                                   input_shape=self.input_shape))\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: batch_normalization() missing 6 required positional arguments: 'x', 'mean', 'variance', 'offset', 'scale', and 'variance_epsilon'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train(seq_length, saved_model=saved_model, image_shape=image_shape,\n",
    "          load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch, loaded_data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
