{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Input, Activation\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "class AVAnalysisModel():   \n",
    "    def __init__(self, seq_length, saved_model=None):\n",
    "        self.seq_length = seq_length\n",
    "        self.input_shape = (seq_length, 80, 80, 3)\n",
    "        \n",
    "        if saved_model is not None:\n",
    "            self.model = load_model(self.saved_model)\n",
    "        else:\n",
    "            self.model = self.lrcn()\n",
    "            \n",
    "        # Now compile the network.\n",
    "        optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def lrcn(self):\n",
    "        \"\"\"Build a CNN into RNN.\n",
    "        Starting version from:\n",
    "            https://github.com/udacity/self-driving-car/blob/master/\n",
    "                steering-models/community-models/chauffeur/models.py\n",
    "        Heavily influenced by VGG-16:\n",
    "            https://arxiv.org/abs/1409.1556\n",
    "        Also known as an LRCN:\n",
    "            https://arxiv.org/pdf/1411.4389.pdf\n",
    "        \"\"\"\n",
    "        def add_default_block(model, kernel_filters, init, reg_lambda):\n",
    "\n",
    "            # conv\n",
    "            model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same',\n",
    "                                             kernel_initializer=init, kernel_regularizer=l2(l=reg_lambda))))\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "            model.add(TimeDistributed(Activation('relu')))\n",
    "            # conv\n",
    "            model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same',\n",
    "                                             kernel_initializer=init, kernel_regularizer=l2(l=reg_lambda))))\n",
    "            model.add(TimeDistributed(BatchNormalization()))\n",
    "            model.add(TimeDistributed(Activation('relu')))\n",
    "            # max pool\n",
    "            model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "            return model\n",
    "\n",
    "        initialiser = 'glorot_uniform'\n",
    "        reg_lambda  = 0.001\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # first (non-default) block\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same',\n",
    "                                         kernel_initializer=initialiser, kernel_regularizer=l2(l=reg_lambda)),\n",
    "                                  input_shape=self.input_shape))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=initialiser, kernel_regularizer=l2(l=reg_lambda))))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        # 2nd-5th (default) blocks\n",
    "        #model = add_default_block(model, 64,  init=initialiser, reg_lambda=reg_lambda)\n",
    "        #model = add_default_block(model, 128, init=initialiser, reg_lambda=reg_lambda)\n",
    "        #model = add_default_block(model, 256, init=initialiser, reg_lambda=reg_lambda)\n",
    "        #model = add_default_block(model, 512, init=initialiser, reg_lambda=reg_lambda)\n",
    "        model = add_default_block(model, 92, init=initialiser, reg_lambda=reg_lambda)\n",
    "        model = add_default_block(model, 196, init=initialiser, reg_lambda=reg_lambda)\n",
    "        \n",
    "        # LSTM output head\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(CuDNNLSTM(256, return_sequences=False))\n",
    "        model.add(Dense(len(VideoClass), activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def load_model(allow_load=True):\n",
    "        models = build_models()\n",
    "        models[0].summary()\n",
    "        if allow_load:\n",
    "            try:\n",
    "                models[0].load_weights(MODEL_FILE)\n",
    "                print('Loaded model from file.')\n",
    "            except:\n",
    "                print('Unable to load model from file.')\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from video_analysis_constants import *\n",
    "from video_dataset import *\n",
    "\n",
    "\n",
    "def train(seq_length, saved_model=None, image_shape=None,\n",
    "          load_to_memory=False, batch_size=32, nb_epoch=100):\n",
    "    \n",
    "    # Helper: TensorBoard\n",
    "    tb = TensorBoard(log_dir=os.path.join(OUT_FOLDER, 'logs'))\n",
    "\n",
    "    # Helper: Stop when we stop learning.\n",
    "    early_stopper = EarlyStopping(patience=5)\n",
    "    \n",
    "    #Helper: Save the model during training\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=MODEL_FILE,\n",
    "        monitor='model',\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    if image_shape is None:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length\n",
    "        )\n",
    "    else:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            image_shape=image_shape\n",
    "        )\n",
    "\n",
    "    # Get samples per epoch.\n",
    "    # Multiply by PERCENT_OF_TRAIN to attempt to guess how much of data.data is the train set.\n",
    "    steps_per_epoch = (len(data.data) * PERCENT_OF_TRAIN) // batch_size\n",
    "\n",
    "    if load_to_memory:\n",
    "        # Get data.\n",
    "        X, y, X_test, y_test = data.get_all_sequences_in_memory(PERCENT_OF_TRAIN)\n",
    "    else:\n",
    "        # Get generators.\n",
    "        #generator = data.frame_generator(batch_size, 'train', PERCENT_OF_TRAIN)\n",
    "        #val_generator = data.frame_generator(batch_size, 'test', PERCENT_OF_TRAIN)\n",
    "        generator, val_generator = data.get_generators(batch_size, PERCENT_OF_TRAIN)\n",
    "\n",
    "    # Get the model.\n",
    "    rm = AVAnalysisModel(seq_length, saved_model)\n",
    "    \n",
    "\n",
    "    # Fit!\n",
    "    if load_to_memory:\n",
    "        # Use standard fit.\n",
    "        rm.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, checkpointer],\n",
    "            epochs=nb_epoch)\n",
    "    else:\n",
    "        # Use fit generator.\n",
    "        rm.model.fit_generator(\n",
    "            generator=generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, checkpointer],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=40,\n",
    "            workers=4)\n",
    " \n",
    "    now = time.strftime(\"%c\")\n",
    "    rm.save(str(now) + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = None  # None or weights file\n",
    "seq_length = 40\n",
    "batch_size = 32\n",
    "nb_epoch = 1000\n",
    "image_shape = (80, 80, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_memory=False\n",
    "train(seq_length, saved_model=saved_model, image_shape=image_shape, load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
