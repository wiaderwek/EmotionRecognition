{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import losses\n",
    "from music_generation_constants import *\n",
    "\n",
    "\n",
    "def one_hot(i, nb_classes):\n",
    "    arr = np.zeros((nb_classes,))\n",
    "    arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def primary_loss(y_true, y_pred):\n",
    "    # 3 separate loss calculations based on if note is played or not\n",
    "    played = y_true[:, :, :, 0]\n",
    "    bce_note = losses.binary_crossentropy(y_true[:, :, :, 0], y_pred[:, :, :, 0])\n",
    "    bce_replay = losses.binary_crossentropy(y_true[:, :, :, 1], tf.multiply(played, y_pred[:, :, :, 1]) + tf.multiply(1 - played, y_true[:, :, :, 1]))\n",
    "    mse = losses.mean_squared_error(y_true[:, :, :, 2], tf.multiply(played, y_pred[:, :, :, 2]) + tf.multiply(1 - played, y_true[:, :, :, 2]))\n",
    "    return bce_note + bce_replay + mse\n",
    "\n",
    "def pitch_pos_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch position of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        note_ranges = tf.range(NUM_NOTES, dtype='float32') / NUM_NOTES\n",
    "        repeated_ranges = tf.tile(note_ranges, [tf.shape(x)[0] * time_steps])\n",
    "        return tf.reshape(repeated_ranges, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_class_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch class of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        pitch_class_matrix = np.array([one_hot(n % OCTAVE, OCTAVE) for n in range(NUM_NOTES)])\n",
    "        pitch_class_matrix = tf.constant(pitch_class_matrix, dtype='float32')\n",
    "        pitch_class_matrix = tf.reshape(pitch_class_matrix, [1, 1, NUM_NOTES, OCTAVE])\n",
    "        return tf.tile(pitch_class_matrix, [tf.shape(x)[0], time_steps, 1, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_bins_f(time_steps):\n",
    "    def f(x):\n",
    "        bins = tf.reduce_sum([x[:, :, i::OCTAVE, 0] for i in range(OCTAVE)], axis=3)\n",
    "        bins = tf.tile(bins, [NUM_OCTAVES, 1, 1])\n",
    "        bins = tf.reshape(bins, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "        return bins\n",
    "    return f\n",
    "\n",
    "def time_axis(dropout):\n",
    "    def f(notes, beat, emotion):\n",
    "        time_steps = int(notes.get_shape()[1])\n",
    "\n",
    "        # TODO: Experiment with when to apply conv\n",
    "        note_octave = TimeDistributed(Conv1D(OCTAVE_UNITS, 2 * OCTAVE, padding='same'))(notes)\n",
    "        note_octave = Activation('tanh')(note_octave)\n",
    "        note_octave = Dropout(dropout)(note_octave)\n",
    "\n",
    "        # Create features for every single note.\n",
    "        note_features = Concatenate()([\n",
    "            Lambda(pitch_pos_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_class_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_bins_f(time_steps))(notes),\n",
    "            note_octave,\n",
    "            TimeDistributed(RepeatVector(NUM_NOTES))(beat)\n",
    "        ])\n",
    "\n",
    "        x = note_features\n",
    "\n",
    "        # [batch, notes, time, features]\n",
    "        x = Permute((2, 1, 3))(x)\n",
    "\n",
    "        # Apply LSTMs\n",
    "        for l in range(TIME_AXIS_LAYERS):\n",
    "            # Integrate emotion\n",
    "            emotion_proj = Dense(int(x.get_shape()[3]))(emotion)\n",
    "            emotion_proj = TimeDistributed(RepeatVector(NUM_NOTES))(emotion_proj)\n",
    "            emotion_proj = Activation('tanh')(emotion_proj)\n",
    "            emotion_proj = Dropout(dropout)(emotion_proj)\n",
    "            emotion_proj = Permute((2, 1, 3))(emotion_proj)\n",
    "            x = Add()([x, emotion_proj])\n",
    "\n",
    "            x = TimeDistributed(LSTM(TIME_AXIS_UNITS, return_sequences=True))(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "        # [batch, time, notes, features]\n",
    "        return Permute((2, 1, 3))(x)\n",
    "    return f\n",
    "\n",
    "def note_axis(dropout):\n",
    "    dense_layer_cache = {}\n",
    "    lstm_layer_cache = {}\n",
    "    note_dense = Dense(2, activation='sigmoid', name='note_dense')\n",
    "    volume_dense = Dense(1, name='volume_dense')\n",
    "\n",
    "    def f(x, chosen, emotion):\n",
    "        time_steps = int(x.get_shape()[1])\n",
    "        \n",
    "        # Shift target one note to the left.\n",
    "        shift_chosen = Lambda(lambda x: tf.pad(x[:, :, :-1, :], tf.constant([[0, 0], [0, 0], [1, 0], [0, 0]])))(chosen)\n",
    "\n",
    "        # [batch, time, notes, 1]\n",
    "        #shift_chosen = Reshape((time_steps, NUM_NOTES, 3))(shift_chosen)\n",
    "        # [batch, time, notes, features + 1]\n",
    "        \n",
    "        x = Concatenate(axis=3)([x, shift_chosen])\n",
    "\n",
    "        for l in range(NOTE_AXIS_LAYERS):\n",
    "            # Integrate emotion\n",
    "            if l not in dense_layer_cache:\n",
    "                dense_layer_cache[l] = Dense(int(x.get_shape()[3]))\n",
    "\n",
    "            emotion_proj = dense_layer_cache[l](emotion)\n",
    "            emotion_proj = TimeDistributed(RepeatVector(NUM_NOTES))(emotion_proj)\n",
    "            emotion_proj = Activation('tanh')(emotion_proj)\n",
    "            emotion_proj = Dropout(dropout)(emotion_proj)\n",
    "            x = Add()([x, emotion_proj])\n",
    "\n",
    "            if l not in lstm_layer_cache:\n",
    "                lstm_layer_cache[l] = LSTM(NOTE_AXIS_UNITS, return_sequences=True)\n",
    "\n",
    "            x = TimeDistributed(lstm_layer_cache[l])(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "        return Concatenate()([note_dense(x), volume_dense(x)])\n",
    "    return f\n",
    "\n",
    "def build_models(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "    notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "    beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "    emotion_in = Input((time_steps, NUM_EMOTIONS))\n",
    "    # Target input for conditioning\n",
    "    chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "    # Dropout inputs\n",
    "    notes = Dropout(input_dropout)(notes_in)\n",
    "    beat = Dropout(input_dropout)(beat_in)\n",
    "    chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "    # Distributed representations\n",
    "    emotion_l = Dense(EMOTION_UNITS, name='emotion')\n",
    "    emotion = emotion_l(emotion_in)\n",
    "\n",
    "    \"\"\" Time axis \"\"\"\n",
    "    time_out = time_axis(dropout)(notes, beat, emotion)\n",
    "\n",
    "    \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "    naxis = note_axis(dropout)\n",
    "    notes_out = naxis(time_out, chosen, emotion)\n",
    "\n",
    "    model = Model([notes_in, chosen_in, beat_in, emotion_in], [notes_out])\n",
    "    model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "\n",
    "    \"\"\" Generation Models \"\"\"\n",
    "    time_model = Model([notes_in, beat_in, emotion_in], [time_out])\n",
    "\n",
    "    note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "    chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "    emotion_gen_in = Input((1, NUM_EMOTIONS), name='emotion_in')\n",
    "\n",
    "    # Dropout inputs\n",
    "    chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    emotion_gen = emotion_l(emotion_gen_in)\n",
    "\n",
    "    note_gen_out = naxis(note_features, chosen_gen, emotion_gen)\n",
    "\n",
    "    note_model = Model([note_features, chosen_gen_in, emotion_gen_in], note_gen_out)\n",
    "\n",
    "    return model, time_model, note_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_or_load(allow_load=True):\n",
    "    models = build_models()\n",
    "    models[0].summary()\n",
    "    if allow_load:\n",
    "        try:\n",
    "            models[0].load_weights(MODEL_FILE)\n",
    "            print('Loaded model from file.')\n",
    "        except:\n",
    "            print('Unable to load model from file.')\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from music_dataset import *\n",
    "from music_generation_constants import *\n",
    "\n",
    "def train(use_data_generator = False):\n",
    "    models = build_or_load()\n",
    "    print('Loading data')\n",
    "    \n",
    "\n",
    "    cbs = [\n",
    "        ModelCheckpoint(MODEL_FILE, monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "        EarlyStopping(monitor='loss', patience=5)\n",
    "        #TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "    ]\n",
    "\n",
    "    print('Training')\n",
    "    if use_data_generator:\n",
    "        generator = data_generator(EMOTIONS, BATCH_SIZE, SEQ_LEN)\n",
    "        models[0].fit_generator(generator=generator,\n",
    "            epochs=1000,\n",
    "            verbose=1,\n",
    "            callbacks=cbs,\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            workers=4)\n",
    "    else:\n",
    "        train_data, train_labels = load_all(EMOTIONS, SEQ_LEN)\n",
    "        models[0].fit(train_data,\n",
    "                      train_labels,\n",
    "                      epochs=1000,\n",
    "                      callbacks=cbs,\n",
    "                      batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 48, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 128, 5)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 48, 3)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "style (Dense)                   multiple             384         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 128, 48, 64)  4672        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 16)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 94)      6110        style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 48, 64)  0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 16)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 128, 48, 94)  0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 48, 1)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 48, 12)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 48, 1)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128, 48, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 128, 48, 16)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 48, 94)  0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 48, 94)  0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128, 48, 94)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128, 256)     16640       style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 48, 128, 94)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 48, 128, 94)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 128, 48, 256) 0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 128, 94)  0           permute_1[0][0]                  \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 48, 256) 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 48, 128, 256) 359424      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 48, 256) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 48, 128, 256) 0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 48, 128, 256) 0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 128, 256) 0           dropout_6[0][0]                  \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 48, 128, 256) 525312      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128, 48, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 multiple             16835       style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 48, 128, 256) 0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 48, 3)   0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 128, 48, 259) 0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 128, 48, 256) 0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 48, 3)   0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 48, 259) 0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 48, 259) 0           permute_4[0][0]                  \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 48, 259) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 multiple             8320        style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 259) 0           concatenate_2[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 128, 48, 128) 0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 128, 48, 128) 198656      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 48, 128) 0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128, 48, 128) 0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128, 48, 128) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 128) 0           dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 128, 48, 128) 131584      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 128, 48, 128) 0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "note_dense (Dense)              multiple             258         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "volume_dense (Dense)            multiple             129         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 48, 3)   0           note_dense[0][0]                 \n",
      "                                                                 volume_dense[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,268,324\n",
      "Trainable params: 1,268,324\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Unable to load model from file.\n",
      "Loading data\n",
      "Training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d8630ad36d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0537f76ba086>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(use_data_generator)\u001b[0m\n\u001b[1;32m     34\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                       batch_size=BATCH_SIZE)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import mido\n",
    "import argparse\n",
    "\n",
    "from music_generation_constants import *\n",
    "from music_dataset import *\n",
    "from tqdm import tqdm\n",
    "from midi_util import midi_encode\n",
    "\n",
    "class MusicGeneration:\n",
    "    \"\"\"\n",
    "    Represents a music generation\n",
    "    \"\"\"\n",
    "    def __init__(self, emotion, default_temp=1):\n",
    "        self.notes_memory = deque([np.zeros((NUM_NOTES, NOTE_UNITS)) for _ in range(SEQ_LEN)], maxlen=SEQ_LEN)\n",
    "        self.beat_memory = deque([np.zeros(NOTES_PER_BAR) for _ in range(SEQ_LEN)], maxlen=SEQ_LEN)\n",
    "        self.emotion_memory = deque([emotion for _ in range(SEQ_LEN)], maxlen=SEQ_LEN)\n",
    "\n",
    "        # The next note being built\n",
    "        self.next_note = np.zeros((NUM_NOTES, NOTE_UNITS))\n",
    "        self.silent_time = NOTES_PER_BAR\n",
    "\n",
    "        # The outputs\n",
    "        self.results = []\n",
    "        # The temperature\n",
    "        self.default_temp = default_temp\n",
    "        self.temperature = default_temp\n",
    "\n",
    "    def build_time_inputs(self):\n",
    "        return (\n",
    "            np.array(self.notes_memory),\n",
    "            np.array(self.beat_memory),\n",
    "            np.array(self.emotion_memory)\n",
    "        )\n",
    "\n",
    "    def build_note_inputs(self, note_features):\n",
    "        # Timesteps = 1 (No temporal dimension)\n",
    "        return (\n",
    "            np.array(note_features),\n",
    "            np.array([self.next_note]),\n",
    "            np.array(list(self.emotion_memory)[-1:])\n",
    "        )\n",
    "\n",
    "    def choose(self, prob, n):\n",
    "        vol = prob[n, -1]\n",
    "        prob = apply_temperature(prob[n, :-1], self.temperature)\n",
    "\n",
    "        # Flip notes randomly\n",
    "        if np.random.random() <= prob[0]:\n",
    "            self.next_note[n, 0] = 1\n",
    "            # Apply volume\n",
    "            self.next_note[n, 2] = vol\n",
    "            # Flip articulation\n",
    "            if np.random.random() <= prob[1]:\n",
    "                self.next_note[n, 1] = 1\n",
    "\n",
    "    def end_time(self, t):\n",
    "        \"\"\"\n",
    "        Finish generation for this time step.\n",
    "        \"\"\"\n",
    "        # Increase temperature while silent.\n",
    "        if np.count_nonzero(self.next_note) == 0:\n",
    "            self.silent_time += 1\n",
    "            if self.silent_time >= NOTES_PER_BAR:\n",
    "                self.temperature += 0.1\n",
    "        else:\n",
    "            self.silent_time = 0\n",
    "            self.temperature = self.default_temp\n",
    "\n",
    "        self.notes_memory.append(self.next_note)\n",
    "        # Consistent with dataset representation\n",
    "        self.beat_memory.append(compute_beat(t, NOTES_PER_BAR))\n",
    "        self.results.append(self.next_note)\n",
    "        # Reset next note\n",
    "        self.next_note = np.zeros((NUM_NOTES, NOTE_UNITS))\n",
    "        return self.results[-1]\n",
    "\n",
    "def apply_temperature(prob, temperature):\n",
    "    \"\"\"\n",
    "    Applies temperature to a sigmoid vector.\n",
    "    \"\"\"\n",
    "    # Apply temperature\n",
    "    if temperature != 1:\n",
    "        # Inverse sigmoid\n",
    "        x = -np.log(1 / prob - 1)\n",
    "        # Apply temperature to sigmoid function\n",
    "        prob = 1 / (1 + np.exp(-x / temperature))\n",
    "    return prob\n",
    "\n",
    "def process_inputs(ins):\n",
    "    ins = list(zip(*ins))\n",
    "    ins = [np.array(i) for i in ins]\n",
    "    return ins\n",
    "\n",
    "def generate(models, num_bars, emotions):\n",
    "    print('Generating with emotions:', emotions)\n",
    "\n",
    "    _, time_model, note_model = models\n",
    "    generations = [MusicGeneration(emotion) for emotion in emotions]\n",
    "\n",
    "    for t in tqdm(range(NOTES_PER_BAR * num_bars)):\n",
    "        # Produce note-invariant features\n",
    "        ins = process_inputs([g.build_time_inputs() for g in generations])\n",
    "        # Pick only the last time step\n",
    "        note_features = time_model.predict(ins)\n",
    "        note_features = np.array(note_features)[:, -1:, :]\n",
    "\n",
    "        # Generate each note conditioned on previous\n",
    "        for n in range(NUM_NOTES):\n",
    "            ins = process_inputs([g.build_note_inputs(note_features[i, :, :, :]) for i, g in enumerate(generations)])\n",
    "            predictions = np.array(note_model.predict(ins))\n",
    "\n",
    "            for i, g in enumerate(generations):\n",
    "                # Remove the temporal dimension\n",
    "                g.choose(predictions[i][-1], n)\n",
    "\n",
    "        # Move one time step\n",
    "        yield [g.end_time(t) for g in generations]\n",
    "\n",
    "def write_file(name, results):\n",
    "    \"\"\"\n",
    "    Takes a list of all notes generated per track and writes it to file\n",
    "    \"\"\"\n",
    "    results = zip(*list(results))\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        fpath = os.path.join(SAMPLES_DIR, name + '_' + str(i) + '.mid')\n",
    "        print('Writing file', fpath)\n",
    "        os.makedirs(os.path.dirname(fpath), exist_ok=True)\n",
    "        mid = midi_encode(unclamp_midi(result))\n",
    "        mid.save(fpath)\n",
    "\n",
    "def main():\n",
    "    #parser = argparse.ArgumentParser(description='Generates music.')\n",
    "    #parser.add_argument('--bars', default=32, type=int, help='Number of bars to generate')\n",
    "    #parser.add_argument('--emotion', default='Neutral', type=str, nargs='+', help='Emotion in music')\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    models = build_or_load()\n",
    "\n",
    "    emotion_id = EMOTIONS.index('Neutral')\n",
    "    emotion_hot = one_hot(emotion_id , NUM_EMOTIONS)\n",
    "    bars = 32\n",
    "\n",
    "    write_file('output', generate(models, bars, [emotion_hot]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
