{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers.merge import Concatenate, Add\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import losses\n",
    "from constants import *\n",
    "\n",
    "\n",
    "def one_hot(i, nb_classes):\n",
    "    arr = np.zeros((nb_classes,))\n",
    "    arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def primary_loss(y_true, y_pred):\n",
    "    # 3 separate loss calculations based on if note is played or not\n",
    "    played = y_true[:, :, :, 0]\n",
    "    bce_note = losses.binary_crossentropy(y_true[:, :, :, 0], y_pred[:, :, :, 0])\n",
    "    bce_replay = losses.binary_crossentropy(y_true[:, :, :, 1], tf.multiply(played, y_pred[:, :, :, 1]) + tf.multiply(1 - played, y_true[:, :, :, 1]))\n",
    "    mse = losses.mean_squared_error(y_true[:, :, :, 2], tf.multiply(played, y_pred[:, :, :, 2]) + tf.multiply(1 - played, y_true[:, :, :, 2]))\n",
    "    return bce_note + bce_replay + mse\n",
    "\n",
    "def pitch_pos_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch position of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        note_ranges = tf.range(NUM_NOTES, dtype='float32') / NUM_NOTES\n",
    "        repeated_ranges = tf.tile(note_ranges, [tf.shape(x)[0] * time_steps])\n",
    "        return tf.reshape(repeated_ranges, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_class_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch class of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        pitch_class_matrix = np.array([one_hot(n % OCTAVE, OCTAVE) for n in range(NUM_NOTES)])\n",
    "        pitch_class_matrix = tf.constant(pitch_class_matrix, dtype='float32')\n",
    "        pitch_class_matrix = tf.reshape(pitch_class_matrix, [1, 1, NUM_NOTES, OCTAVE])\n",
    "        return tf.tile(pitch_class_matrix, [tf.shape(x)[0], time_steps, 1, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_bins_f(time_steps):\n",
    "    def f(x):\n",
    "        bins = tf.reduce_sum([x[:, :, i::OCTAVE, 0] for i in range(OCTAVE)], axis=3)\n",
    "        bins = tf.tile(bins, [NUM_OCTAVES, 1, 1])\n",
    "        bins = tf.reshape(bins, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "        return bins\n",
    "    return f\n",
    "\n",
    "def time_axis(dropout):\n",
    "    def f(notes, beat, style):\n",
    "        time_steps = int(notes.get_shape()[1])\n",
    "\n",
    "        # TODO: Experiment with when to apply conv\n",
    "        note_octave = TimeDistributed(Conv1D(OCTAVE_UNITS, 2 * OCTAVE, padding='same'))(notes)\n",
    "        note_octave = Activation('tanh')(note_octave)\n",
    "        note_octave = Dropout(dropout)(note_octave)\n",
    "\n",
    "        # Create features for every single note.\n",
    "        note_features = Concatenate()([\n",
    "            Lambda(pitch_pos_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_class_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_bins_f(time_steps))(notes),\n",
    "            note_octave,\n",
    "            TimeDistributed(RepeatVector(NUM_NOTES))(beat)\n",
    "        ])\n",
    "\n",
    "        x = note_features\n",
    "\n",
    "        # [batch, notes, time, features]\n",
    "        x = Permute((2, 1, 3))(x)\n",
    "\n",
    "        # Apply LSTMs\n",
    "        for l in range(TIME_AXIS_LAYERS):\n",
    "            # Integrate style\n",
    "            style_proj = Dense(int(x.get_shape()[3]))(style)\n",
    "            style_proj = TimeDistributed(RepeatVector(NUM_NOTES))(style_proj)\n",
    "            style_proj = Activation('tanh')(style_proj)\n",
    "            style_proj = Dropout(dropout)(style_proj)\n",
    "            style_proj = Permute((2, 1, 3))(style_proj)\n",
    "            x = Add()([x, style_proj])\n",
    "\n",
    "            x = TimeDistributed(LSTM(TIME_AXIS_UNITS, return_sequences=True))(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "        # [batch, time, notes, features]\n",
    "        return Permute((2, 1, 3))(x)\n",
    "    return f\n",
    "\n",
    "def note_axis(dropout):\n",
    "    dense_layer_cache = {}\n",
    "    lstm_layer_cache = {}\n",
    "    note_dense = Dense(2, activation='sigmoid', name='note_dense')\n",
    "    volume_dense = Dense(1, name='volume_dense')\n",
    "\n",
    "    def f(x, chosen, style):\n",
    "        time_steps = int(x.get_shape()[1])\n",
    "        \n",
    "        # Shift target one note to the left.\n",
    "        shift_chosen = Lambda(lambda x: tf.pad(x[:, :, :-1, :], tf.constant([[0, 0], [0, 0], [1, 0], [0, 0]])))(chosen)\n",
    "\n",
    "        # [batch, time, notes, 1]\n",
    "        #shift_chosen = Reshape((time_steps, NUM_NOTES, 3))(shift_chosen)\n",
    "        # [batch, time, notes, features + 1]\n",
    "        \n",
    "        x = Concatenate(axis=3)([x, shift_chosen])\n",
    "\n",
    "        for l in range(NOTE_AXIS_LAYERS):\n",
    "            # Integrate style\n",
    "            if l not in dense_layer_cache:\n",
    "                dense_layer_cache[l] = Dense(int(x.get_shape()[3]))\n",
    "\n",
    "            style_proj = dense_layer_cache[l](style)\n",
    "            style_proj = TimeDistributed(RepeatVector(NUM_NOTES))(style_proj)\n",
    "            style_proj = Activation('tanh')(style_proj)\n",
    "            style_proj = Dropout(dropout)(style_proj)\n",
    "            x = Add()([x, style_proj])\n",
    "\n",
    "            if l not in lstm_layer_cache:\n",
    "                lstm_layer_cache[l] = LSTM(NOTE_AXIS_UNITS, return_sequences=True)\n",
    "\n",
    "            x = TimeDistributed(lstm_layer_cache[l])(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "        return Concatenate()([note_dense(x), volume_dense(x)])\n",
    "    return f\n",
    "\n",
    "def build_models(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "    notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "    beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "    style_in = Input((time_steps, NUM_EMOTIONS))\n",
    "    # Target input for conditioning\n",
    "    chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "    # Dropout inputs\n",
    "    notes = Dropout(input_dropout)(notes_in)\n",
    "    beat = Dropout(input_dropout)(beat_in)\n",
    "    chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "    # Distributed representations\n",
    "    style_l = Dense(STYLE_UNITS, name='style')\n",
    "    style = style_l(style_in)\n",
    "\n",
    "    \"\"\" Time axis \"\"\"\n",
    "    time_out = time_axis(dropout)(notes, beat, style)\n",
    "\n",
    "    \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "    naxis = note_axis(dropout)\n",
    "    notes_out = naxis(time_out, chosen, style)\n",
    "\n",
    "    model = Model([notes_in, chosen_in, beat_in, style_in], [notes_out])\n",
    "    model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "\n",
    "    \"\"\" Generation Models \"\"\"\n",
    "    time_model = Model([notes_in, beat_in, style_in], [time_out])\n",
    "\n",
    "    note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "    chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "    style_gen_in = Input((1, NUM_EMOTIONS), name='style_in')\n",
    "\n",
    "    # Dropout inputs\n",
    "    chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    style_gen = style_l(style_gen_in)\n",
    "\n",
    "    note_gen_out = naxis(note_features, chosen_gen, style_gen)\n",
    "\n",
    "    note_model = Model([note_features, chosen_gen_in, style_gen_in], note_gen_out)\n",
    "\n",
    "    return model, time_model, note_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_or_load(allow_load=True):\n",
    "    models = build_models()\n",
    "    models[0].summary()\n",
    "    if allow_load:\n",
    "        try:\n",
    "            models[0].load_weights(MODEL_FILE)\n",
    "            print('Loaded model from file.')\n",
    "        except:\n",
    "            print('Unable to load model from file.')\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import argparse\n",
    "import midi\n",
    "import os\n",
    "\n",
    "from music_dataset import *\n",
    "from constants import *\n",
    "\n",
    "def train(use_data_generator = False):\n",
    "    models = build_or_load()\n",
    "    print('Loading data')\n",
    "    \n",
    "\n",
    "    cbs = [\n",
    "        ModelCheckpoint(MODEL_FILE, monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "        EarlyStopping(monitor='loss', patience=5),\n",
    "        TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "    ]\n",
    "\n",
    "    print('Training')\n",
    "    if use_data_generator:\n",
    "        generator = data_generator(EMOTIONS, BATCH_SIZE, SEQ_LEN)\n",
    "        models[0].fit_generator(generator=generator,\n",
    "            epochs=1000,\n",
    "            verbose=1,\n",
    "            callbacks=cbs,\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            workers=4)\n",
    "    else:\n",
    "        train_data, train_labels = load_all(EMOTIONS, SEQ_LEN)\n",
    "        models[0].fit(train_data,\n",
    "                      train_labels,\n",
    "                      epochs=1000,\n",
    "                      callbacks=cbs,\n",
    "                      batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 48, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 128, 5)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 48, 3)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "style (Dense)                   multiple             384         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 128, 48, 64)  4672        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 16)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 94)      6110        style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 48, 64)  0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 16)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 128, 48, 94)  0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 48, 1)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 48, 12)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 48, 1)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128, 48, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 128, 48, 16)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 48, 94)  0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 48, 94)  0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128, 48, 94)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128, 256)     16640       style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 48, 128, 94)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 48, 128, 94)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 128, 48, 256) 0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 128, 94)  0           permute_1[0][0]                  \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 48, 256) 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 48, 128, 256) 359424      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 48, 256) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 48, 128, 256) 0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 48, 128, 256) 0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 128, 256) 0           dropout_6[0][0]                  \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 48, 128, 256) 525312      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128, 48, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 multiple             16835       style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 48, 128, 256) 0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 48, 3)   0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 128, 48, 259) 0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 128, 48, 256) 0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 48, 3)   0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 48, 259) 0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 48, 259) 0           permute_4[0][0]                  \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 48, 259) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 multiple             8320        style[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 259) 0           concatenate_2[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 128, 48, 128) 0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 128, 48, 128) 198656      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 48, 128) 0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128, 48, 128) 0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128, 48, 128) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 128) 0           dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 128, 48, 128) 131584      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 128, 48, 128) 0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "note_dense (Dense)              multiple             258         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "volume_dense (Dense)            multiple             129         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 48, 3)   0           note_dense[0][0]                 \n",
      "                                                                 volume_dense[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,268,324\n",
      "Trainable params: 1,268,324\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Unable to load model from file.\n",
      "Loading data\n",
      "Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[272384,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node dense_2/MatMul (defined at /home/tomasz/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_11158]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-326b49521e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0c2be8ff6286>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(use_data_generator)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             workers=4)\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMOTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[272384,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node dense_2/MatMul (defined at /home/tomasz/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_11158]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
