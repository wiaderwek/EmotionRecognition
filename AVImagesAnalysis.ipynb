{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 763.35it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 160.97it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 136.81it/s]\n",
      "100%|██████████| 121/121 [00:00<00:00, 166.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH_TO_PROJECT = os.getcwd()\n",
    "FOLDR_WITH_DATASET = \"DataSet\"\n",
    "FOLDERS_WITH_IMAGES = [\"A\", \"N\", \"H\", \"P\"]\n",
    "RESULT_FILE_EXTENSION = \".txt\"\n",
    "PATH_TO_DATASET = os.path.join(PATH_TO_PROJECT, FOLDR_WITH_DATASET)\n",
    "\n",
    "IMG_SIZE = 100\n",
    "\n",
    "\n",
    "\n",
    "def create_training_all_data(FOLDERS_WITH_IMAGES):\n",
    "    training_data = []\n",
    "    results = []\n",
    "    for folder in FOLDERS_WITH_IMAGES:\n",
    "        path_to_images = os.path.join(PATH_TO_DATASET, folder)\n",
    "        path_to_result = os.path.join(PATH_TO_DATASET, folder+RESULT_FILE_EXTENSION)\n",
    "        list_of_results = open(path_to_result).readlines()\n",
    "        list_of_results.pop(0)\n",
    "        for res in list_of_results:\n",
    "            splitted_res = res.split(\"\\t\")\n",
    "            valency = splitted_res[1]\n",
    "            arousal = splitted_res[2]\n",
    "            results.append([valency, arousal])\n",
    "        index = 0\n",
    "        for img in tqdm(os.listdir(path_to_images)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path_to_images, img))  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, results[index]])  # add this to our training_data\n",
    "                index += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                #print(\"general exception\", e, os.path.join(categoty_path, img))\n",
    "    return training_data\n",
    "\n",
    "\n",
    "training_data = create_training_all_data(FOLDSERS_WITH_IMAGES)\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "LVLA = [1, 0, 0, 0]\n",
    "LVHA = [0, 1, 0, 0]\n",
    "HVLA = [0, 0, 1, 0]\n",
    "HVHA = [0, 0, 0, 1]\n",
    "\n",
    "def prepare_results(y, X, training_data):\n",
    "    for features,label in training_data:\n",
    "        X.append(features)\n",
    "        if float(label[0]) < 50.0 and float(label[1]) < 50.0:\n",
    "            y.append(LVLA)\n",
    "        elif float(label[0]) < 50.0 and float(label[1]) >= 50.0:\n",
    "            y.append(LVHA)\n",
    "        elif float(label[0]) >= 50.0 and float(label[1]) < 50.0:\n",
    "            y.append(HVLA)\n",
    "        else:\n",
    "            y.append(HVHA)\n",
    "    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "prepare_results(y, X, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 351 samples, validate on 88 samples\n",
      "Epoch 1/10\n",
      "351/351 [==============================] - 5s 15ms/sample - loss: 0.3346 - accuracy: 0.8618 - val_loss: 0.3154 - val_accuracy: 0.8977\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 4s 12ms/sample - loss: 0.2920 - accuracy: 0.8939 - val_loss: 0.2782 - val_accuracy: 0.8977\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.models as Models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "X = tf.keras.utils.normalize(X, axis=1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), input_shape=X.shape[1:], data_format='channels_last', strides=1))\n",
    "model.add(Activation('selu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(196, (3, 3), strides=1))\n",
    "model.add(Activation('selu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=3))\n",
    "\n",
    "model.add(Conv2D(92, (3, 3), strides=1))\n",
    "model.add(Activation('selu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=3))\n",
    "\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, np.array(y), batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 934.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 4ms/sample - loss: 0.6197 - accuracy: 0.7970\n",
      "0.7265095468750573\n",
      "0.7969925\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_FOLDERS = [\"Sn\"]\n",
    "validation_data = create_training_all_data(VALIDATION_FOLDERS)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "prepare_results(y_val, X_val, validation_data)\n",
    "X_val = tf.keras.utils.normalize(X_val, axis=1)\n",
    "                \n",
    "val_loss, val_acc = model.evaluate(X_val, np.array(y_val))\n",
    "print(val_loss)\n",
    "print(val_acc)\n",
    "\n",
    "counter = 0\n",
    "predictions = model.predict(X_val)\n",
    "for i in range(len(y_val)):\n",
    "    if np.argmax(predictions[i]) != np.argmax(y_val[i]):\n",
    "        counter += 1\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
